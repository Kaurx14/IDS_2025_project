{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9ebef9f",
   "metadata": {},
   "source": [
    "# Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a58c1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "if \"id\" in train.columns:\n",
    "    train = train.drop(columns=[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d2cd7e",
   "metadata": {},
   "source": [
    "## Feature preparation & scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "966d435a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender 3\n",
      "marital_status 4\n",
      "education_level 5\n",
      "employment_status 5\n",
      "loan_purpose 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((80000, 30), (20000, 30))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Separate target and features\n",
    "\n",
    "# I guess makes sense to drop the \"grade_subgrade\" column since it has 30 unique values -> very many columns when one-hot encoding\n",
    "# Or if not drop, then at least group the categories somehow. Maybe this is better. This way we at least account for this feature.\n",
    "X = train.drop(columns=[\"loan_paid_back\", \"grade_subgrade\"])\n",
    "y = train[\"loan_paid_back\"]\n",
    "\n",
    "train_small = train.sample(100_000, random_state=42)\n",
    "X_small = train_small.drop(columns=[\"loan_paid_back\"])\n",
    "y_small = train_small[\"loan_paid_back\"]\n",
    "\n",
    "# Categorical & numeric columns already detected earlier\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include=[\"float64\", \"int64\"]).columns.tolist()\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(col, X[col].nunique())\n",
    "\n",
    "# Preprocessor pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Train-validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_small, y_small, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Fit preprocessing\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_val_processed = preprocessor.transform(X_val)\n",
    "\n",
    "X_train_processed.shape, X_val_processed.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aee3b5",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d09350f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with k=75\n",
      "KNN (k=75) - AUC: 0.89901, Accuracy: 0.88950, Precision: 0.88497, Recall: 0.99029\n",
      "Starting training with k=125\n",
      "KNN (k=125) - AUC: 0.89968, Accuracy: 0.88655, Precision: 0.88078, Recall: 0.99217\n",
      "Starting training with k=250\n",
      "KNN (k=250) - AUC: 0.89948, Accuracy: 0.87720, Precision: 0.87102, Recall: 0.99324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{75: {'AUC': 0.8990111035175692,\n",
       "  'Accuracy': 0.8895,\n",
       "  'Precision': 0.8849706129303107,\n",
       "  'Recall': 0.9902912621359223},\n",
       " 125: {'AUC': 0.8996806909165844,\n",
       "  'Accuracy': 0.88655,\n",
       "  'Precision': 0.8807829181494662,\n",
       "  'Recall': 0.99217037269026},\n",
       " 250: {'AUC': 0.8994824179751943,\n",
       "  'Accuracy': 0.8772,\n",
       "  'Precision': 0.8710244438341115,\n",
       "  'Recall': 0.9932352020043846}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "k_values = [75,125,250]\n",
    "\n",
    "results_knn = {}\n",
    "\n",
    "for k in k_values:\n",
    "    print(f\"Starting training with k={k}\")\n",
    "    knn = Pipeline(steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"model\", KNeighborsClassifier(n_neighbors=k))\n",
    "    ])\n",
    "\n",
    "    knn.fit(X_train, y_train)\n",
    "    predictions_proba = knn.predict_proba(X_val)[:, 1]\n",
    "    predictions = knn.predict(X_val)\n",
    "    \n",
    "    auc = roc_auc_score(y_val, predictions_proba)\n",
    "    accuracy = accuracy_score(y_val, predictions)\n",
    "    precision = precision_score(y_val, predictions)\n",
    "    recall = recall_score(y_val, predictions)\n",
    "    \n",
    "    results_knn[k] = {\n",
    "        \"AUC\": auc,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall\n",
    "    }\n",
    "    print(f\"KNN (k={k}) - AUC: {auc:.5f}, Accuracy: {accuracy:.5f}, Precision: {precision:.5f}, Recall: {recall:.5f}\")\n",
    "\n",
    "results_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c51cb7e",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32d21330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with Linear SVM\n",
      "Starting fitting\n",
      "Starting predicting\n",
      "Starting metric calculations\n",
      "Linear SVM - AUC: 0.89206, Accuracy: 0.89745, Precision: 0.89886, Recall: 0.98202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Linear SVM': {'AUC': 0.8920575562015888,\n",
       "  'Accuracy': 0.89745,\n",
       "  'Precision': 0.8988648090815273,\n",
       "  'Recall': 0.9820231756968368}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Sample 25,000 rows for SVM training (SVM is computationally expensive)\n",
    "svm_sample_size = 25000\n",
    "svm_sample_indices = X_train.sample(n=min(svm_sample_size, len(X_train)), random_state=42).index\n",
    "X_train_svm = X_train.loc[svm_sample_indices]\n",
    "y_train_svm = y_train.loc[svm_sample_indices]\n",
    "\n",
    "svm_models = [\n",
    "    (\"Linear SVM\", SVC(kernel=\"linear\", probability=True, C=1))\n",
    "]\n",
    "\n",
    "results_svm = {}\n",
    "\n",
    "for name, model in svm_models:\n",
    "    print(f\"Starting with {name}\")\n",
    "    classifier = Pipeline(steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    print(f\"Starting fitting\")\n",
    "    classifier.fit(X_train_svm, y_train_svm)\n",
    "    print(f\"Starting predicting\")\n",
    "    preds_proba = classifier.predict_proba(X_val)[:, 1]\n",
    "    preds = classifier.predict(X_val)\n",
    "    print(f\"Starting metric calculations\")\n",
    "    auc = roc_auc_score(y_val, preds_proba)\n",
    "    accuracy = accuracy_score(y_val, preds)\n",
    "    precision = precision_score(y_val, preds)\n",
    "    recall = recall_score(y_val, preds)\n",
    "    \n",
    "    results_svm[name] = {\n",
    "        \"AUC\": auc,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall\n",
    "    }\n",
    "    print(f\"{name} - AUC: {auc:.5f}, Accuracy: {accuracy:.5f}, Precision: {precision:.5f}, Recall: {recall:.5f}\")\n",
    "\n",
    "results_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b1a718",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "772fc088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB: est=200, lr=0.05, depth=3 - AUC: 0.91680, Accuracy: 0.90265, Precision: 0.90674, Recall: 0.97870\n",
      "GB: est=300, lr=0.1, depth=3 - AUC: 0.91963, Accuracy: 0.90465, Precision: 0.90952, Recall: 0.97783\n",
      "GB: est=500, lr=0.1, depth=4 - AUC: 0.92057, Accuracy: 0.90565, Precision: 0.91144, Recall: 0.97670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'GB: est=200, lr=0.05, depth=3': {'AUC': 0.9167968965569432,\n",
       "  'Accuracy': 0.90265,\n",
       "  'Precision': 0.9067432683379758,\n",
       "  'Recall': 0.978703413717507},\n",
       " 'GB: est=300, lr=0.1, depth=3': {'AUC': 0.9196331814754317,\n",
       "  'Accuracy': 0.90465,\n",
       "  'Precision': 0.9095199254253088,\n",
       "  'Recall': 0.9778264954588162},\n",
       " 'GB: est=500, lr=0.1, depth=4': {'AUC': 0.9205683125765743,\n",
       "  'Accuracy': 0.90565,\n",
       "  'Precision': 0.9114449380406827,\n",
       "  'Recall': 0.9766990291262136}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "params = [\n",
    "    {\"n_estimators\": 200, \"learning_rate\": 0.05, \"max_depth\": 3},\n",
    "    {\"n_estimators\": 300, \"learning_rate\": 0.1,  \"max_depth\": 3},\n",
    "    {\"n_estimators\": 500, \"learning_rate\": 0.1,  \"max_depth\": 4},\n",
    "]\n",
    "\n",
    "results_gb = {}\n",
    "\n",
    "for p in params:\n",
    "    model = GradientBoostingClassifier(\n",
    "        n_estimators=p[\"n_estimators\"],\n",
    "        learning_rate=p[\"learning_rate\"],\n",
    "        max_depth=p[\"max_depth\"]\n",
    "    )\n",
    "\n",
    "    classifier = Pipeline(steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "    preds_proba = classifier.predict_proba(X_val)[:, 1]\n",
    "    preds = classifier.predict(X_val)\n",
    "    \n",
    "    auc = roc_auc_score(y_val, preds_proba)\n",
    "    accuracy = accuracy_score(y_val, preds)\n",
    "    precision = precision_score(y_val, preds)\n",
    "    recall = recall_score(y_val, preds)\n",
    "    \n",
    "    name = f\"GB: est={p['n_estimators']}, lr={p['learning_rate']}, depth={p['max_depth']}\"\n",
    "    results_gb[name] = {\n",
    "        \"AUC\": auc,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall\n",
    "    }\n",
    "    print(f\"{name} - AUC: {auc:.5f}, Accuracy: {accuracy:.5f}, Precision: {precision:.5f}, Recall: {recall:.5f}\")\n",
    "\n",
    "results_gb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4ce981",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14ff2e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "XGBoost installation check complete.\n"
     ]
    }
   ],
   "source": [
    "# Install xgboost in the current Python environment (if not already installed)\n",
    "# This ensures it's installed in the same environment that Jupyter is using\n",
    "# Using %pip ensures installation in the kernel's Python environment\n",
    "%pip install xgboost --quiet\n",
    "print(\"XGBoost installation check complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a467b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost: est=200, lr=0.05, depth=3\n",
      "XGBoost: est=200, lr=0.05, depth=3 - AUC: 0.91694, Accuracy: 0.90285, Precision: 0.90681, Recall: 0.97889\n",
      "\n",
      "Training XGBoost: est=300, lr=0.1, depth=4\n",
      "XGBoost: est=300, lr=0.1, depth=4 - AUC: 0.91876, Accuracy: 0.90210, Precision: 0.90768, Recall: 0.97670\n",
      "\n",
      "Training XGBoost: est=500, lr=0.1, depth=5\n",
      "XGBoost: est=500, lr=0.1, depth=5 - AUC: 0.91744, Accuracy: 0.90285, Precision: 0.90957, Recall: 0.97526\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'XGBoost: est=200, lr=0.05, depth=3': {'AUC': 0.9169449046493046,\n",
       "  'Accuracy': 0.90285,\n",
       "  'Precision': 0.9068121155854706,\n",
       "  'Recall': 0.9788913247729408},\n",
       " 'XGBoost: est=300, lr=0.1, depth=4': {'AUC': 0.9187580173637266,\n",
       "  'Accuracy': 0.9021,\n",
       "  'Precision': 0.9076779789277606,\n",
       "  'Recall': 0.9766990291262136},\n",
       " 'XGBoost: est=500, lr=0.1, depth=5': {'AUC': 0.9174411807737729,\n",
       "  'Accuracy': 0.90285,\n",
       "  'Precision': 0.9095688748685594,\n",
       "  'Recall': 0.9752583777012214}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Prepare data for XGBoost native categorical handling\n",
    "# Convert categorical columns to pandas category dtype (XGBoost native format)\n",
    "X_train_xgb = X_train.copy()\n",
    "X_val_xgb = X_val.copy()\n",
    "\n",
    "# Get categorical columns (same as defined earlier)\n",
    "categorical_cols_xgb = X_train_xgb.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "# Convert categorical columns to category dtype for XGBoost native handling\n",
    "for col in categorical_cols_xgb:\n",
    "    X_train_xgb[col] = X_train_xgb[col].astype(\"category\")\n",
    "    X_val_xgb[col] = X_val_xgb[col].astype(\"category\")\n",
    "\n",
    "# XGBoost parameters to try\n",
    "xgb_params = [\n",
    "    {\"n_estimators\": 200, \"learning_rate\": 0.05, \"max_depth\": 3, \"subsample\": 0.8},\n",
    "    {\"n_estimators\": 300, \"learning_rate\": 0.1, \"max_depth\": 4, \"subsample\": 0.8},\n",
    "    {\"n_estimators\": 500, \"learning_rate\": 0.1, \"max_depth\": 5, \"subsample\": 0.9},\n",
    "]\n",
    "\n",
    "results_xgb = {}\n",
    "\n",
    "for p in xgb_params:\n",
    "    # enable_categorical=True tells XGBoost to use native categorical handling\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=p[\"n_estimators\"],\n",
    "        learning_rate=p[\"learning_rate\"],\n",
    "        max_depth=p[\"max_depth\"],\n",
    "        subsample=p[\"subsample\"],\n",
    "        random_state=42,\n",
    "        eval_metric=\"logloss\",\n",
    "        enable_categorical=True  # Enable native categorical feature handling\n",
    "    )\n",
    "\n",
    "    print(f\"Training XGBoost: est={p['n_estimators']}, lr={p['learning_rate']}, depth={p['max_depth']}\")\n",
    "    model.fit(X_train_xgb, y_train)\n",
    "    \n",
    "    preds_proba = model.predict_proba(X_val_xgb)[:, 1]\n",
    "    preds = model.predict(X_val_xgb)\n",
    "    \n",
    "    auc = roc_auc_score(y_val, preds_proba)\n",
    "    accuracy = accuracy_score(y_val, preds)\n",
    "    precision = precision_score(y_val, preds)\n",
    "    recall = recall_score(y_val, preds)\n",
    "    \n",
    "    name = f\"XGBoost: est={p['n_estimators']}, lr={p['learning_rate']}, depth={p['max_depth']}\"\n",
    "    results_xgb[name] = {\n",
    "        \"AUC\": auc,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall\n",
    "    }\n",
    "    print(f\"{name} - AUC: {auc:.5f}, Accuracy: {accuracy:.5f}, Precision: {precision:.5f}, Recall: {recall:.5f}\\n\")\n",
    "\n",
    "results_xgb\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
